{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Imports",
   "id": "f81470a326610dc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:32.178435Z",
     "start_time": "2025-10-14T17:26:30.786949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import string"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset",
   "id": "ee8ffdd8ecfac84d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:32.268715Z",
     "start_time": "2025-10-14T17:26:32.197557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "dataset.head()"
   ],
   "id": "76cb74007a67030c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0                                        source_text  \\\n",
       "0           0  Researchers have discovered a new species of b...   \n",
       "1           1  The moon orbits the Earth in approximately 27....   \n",
       "2           2  Water is composed of two hydrogen atoms and on...   \n",
       "3           3          The history of Rome dates back to 753 BC.   \n",
       "4           4  Pluto was once considered the ninth planet in ...   \n",
       "\n",
       "                                    plagiarized_text  label  \n",
       "0  Scientists have found a previously unknown but...      1  \n",
       "1  Our natural satellite takes around 27.3 days t...      1  \n",
       "2  H2O consists of 2 hydrogen atoms and 1 oxygen ...      1  \n",
       "3  Rome has a long history that can be traced bac...      1  \n",
       "4  In the past, Pluto was classified as the ninth...      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_text</th>\n",
       "      <th>plagiarized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Researchers have discovered a new species of b...</td>\n",
       "      <td>Scientists have found a previously unknown but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The moon orbits the Earth in approximately 27....</td>\n",
       "      <td>Our natural satellite takes around 27.3 days t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Water is composed of two hydrogen atoms and on...</td>\n",
       "      <td>H2O consists of 2 hydrogen atoms and 1 oxygen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The history of Rome dates back to 753 BC.</td>\n",
       "      <td>Rome has a long history that can be traced bac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pluto was once considered the ninth planet in ...</td>\n",
       "      <td>In the past, Pluto was classified as the ninth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:32.303763Z",
     "start_time": "2025-10-14T17:26:32.293932Z"
    }
   },
   "cell_type": "code",
   "source": "dataset['label'].value_counts()",
   "id": "f76e5cc0f1b6ba37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    187\n",
       "1    183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Seperating into Training and Test Dataset",
   "id": "9e306c1150eb2ad5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:33.837002Z",
     "start_time": "2025-10-14T17:26:32.340758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "9816d195017a2761",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:33.854351Z",
     "start_time": "2025-10-14T17:26:33.844588Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_train)",
   "id": "5afc8007d096611a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0\n",
      " 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1\n",
      " 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0\n",
      " 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1\n",
      " 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0\n",
      " 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:33.890485Z",
     "start_time": "2025-10-14T17:26:33.885748Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_test)",
   "id": "415408cf26e5435d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vectorization",
   "id": "3323a73e2fa8847c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:33.955247Z",
     "start_time": "2025-10-14T17:26:33.912400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(dataset[\"source_text\"] + \" \" + dataset[\"plagiarized_text\"])"
   ],
   "id": "adfd77cfb1277bae",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Applying logistic regression",
   "id": "3cbb15640161a873"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.187283Z",
     "start_time": "2025-10-14T17:26:33.961313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "data[\"combined_text\"] = data[\"source_text\"] + \" \" + data[\"plagiarized_text\"]\n",
    "\n",
    "X_raw = data[\"combined_text\"]\n",
    "y = data[\"label\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X_raw)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "3990163722ad7bb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8648648648648649\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        35\n",
      "           1       0.87      0.87      0.87        39\n",
      "\n",
      "    accuracy                           0.86        74\n",
      "   macro avg       0.86      0.86      0.86        74\n",
      "weighted avg       0.86      0.86      0.86        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30  5]\n",
      " [ 5 34]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random Forest Model",
   "id": "9726aeb463837560"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.551788Z",
     "start_time": "2025-10-14T17:26:34.195771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "id": "3aad945213a6d51f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8243243243243243\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81        35\n",
      "           1       0.81      0.87      0.84        39\n",
      "\n",
      "    accuracy                           0.82        74\n",
      "   macro avg       0.83      0.82      0.82        74\n",
      "weighted avg       0.83      0.82      0.82        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27  8]\n",
      " [ 5 34]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Naiv Bays Model",
   "id": "391fe1a3383a821d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.590146Z",
     "start_time": "2025-10-14T17:26:34.563358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "id": "51dbaa4db2d3ac5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8513513513513513\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.83        35\n",
      "           1       0.80      0.95      0.87        39\n",
      "\n",
      "    accuracy                           0.85        74\n",
      "   macro avg       0.87      0.85      0.85        74\n",
      "weighted avg       0.86      0.85      0.85        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26  9]\n",
      " [ 2 37]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SVM",
   "id": "54f844512b9b56c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.630774Z",
     "start_time": "2025-10-14T17:26:34.597711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate the model\n",
    "model = SVC(kernel='linear', random_state=42)\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "id": "fba8476c2d0815cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8648648648648649\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84        35\n",
      "           1       0.82      0.95      0.88        39\n",
      "\n",
      "    accuracy                           0.86        74\n",
      "   macro avg       0.88      0.86      0.86        74\n",
      "weighted avg       0.87      0.86      0.86        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27  8]\n",
      " [ 2 37]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.681248Z",
     "start_time": "2025-10-14T17:26:34.637396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear', random_state=42, probability=True)\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "id": "e6da34d7e4f0dd64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8648648648648649\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84        35\n",
      "           1       0.82      0.95      0.88        39\n",
      "\n",
      "    accuracy                           0.86        74\n",
      "   macro avg       0.88      0.86      0.86        74\n",
      "weighted avg       0.87      0.86      0.86        74\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27  8]\n",
      " [ 2 37]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save SVM and Vectorizor",
   "id": "45120ad438b63958"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.698168Z",
     "start_time": "2025-10-14T17:26:34.688191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open(\"model.pkl\",'wb'))\n",
    "pickle.dump(tfidf_vectorizer, open('tfidf_vectorizer.pkl','wb'))"
   ],
   "id": "4ac7e50019cd26ed",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Shingling",
   "id": "568543415a3ea1d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.718960Z",
     "start_time": "2025-10-14T17:26:34.710582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def shingling(text, k=3):\n",
    "    words = text.lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    shingles = set()\n",
    "    for i in range(len(words) - k + 1):\n",
    "        shingles.add(' '.join(words[i:i+k]))\n",
    "    return shingles\n",
    "\n",
    "def jaccard_similarity(text1, text2, k=3):\n",
    "    shingles1 = shingling(text1, k)\n",
    "    shingles2 = shingling(text2, k)\n",
    "\n",
    "    intersection = len(shingles1.intersection(shingles2))\n",
    "    union = len(shingles1.union(shingles2))\n",
    "\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union"
   ],
   "id": "18359a66dbc0b36e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.732154Z",
     "start_time": "2025-10-14T17:26:34.725677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texts = dataset['source_text'].tolist() + dataset['plagiarized_text'].tolist()\n",
    "\n",
    "print(jaccard_similarity(texts[0], texts[len(dataset)]))"
   ],
   "id": "78768a12245ed863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05263157894736842\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.758200Z",
     "start_time": "2025-10-14T17:26:34.752471Z"
    }
   },
   "cell_type": "code",
   "source": "print(jaccard_similarity(texts[0], texts[1]))",
   "id": "ab7b559b49ee39d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load Model and Vectorizer",
   "id": "d99f394763fc6aa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.808623Z",
     "start_time": "2025-10-14T17:26:34.779874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = pickle.load(open('model.pkl','rb'))\n",
    "tfidf_vectorizer = pickle.load(open('tfidf_vectorizer.pkl','rb'))"
   ],
   "id": "4d8ea30a2cabe0eb",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:34.876957Z",
     "start_time": "2025-10-14T17:26:34.814858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "corpus = data[\"combined_text\"]\n",
    "\n",
    "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,5), max_features=20000)\n",
    "X_char = tfidf_char.fit_transform(corpus)\n",
    "\n",
    "X_combined = hstack([X, X_char])"
   ],
   "id": "91e56b92268a362b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SBERT",
   "id": "4f94f44e476d52e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:48.025877Z",
     "start_time": "2025-10-14T17:26:34.884173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -U sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def chunk_text(text, chunk_size=80):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "def semantic_similarity(doc1, doc2):\n",
    "    chunks1, chunks2 = chunk_text(doc1), chunk_text(doc2)\n",
    "    emb1, emb2 = sbert.encode(chunks1), sbert.encode(chunks2)\n",
    "    sims = cosine_similarity(emb1, emb2)\n",
    "    return float(np.max(sims))"
   ],
   "id": "40b6d820298b4815",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\arghy\\miniconda3\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arghy\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arghy\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Detection System",
   "id": "2788fd8fc9116299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:48.036881Z",
     "start_time": "2025-10-14T17:26:48.031969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect(input_text, similarity_threshold=0.6):\n",
    "    source_text_example = dataset['source_text'][0]\n",
    "\n",
    "    sim_score = semantic_similarity(source_text_example, input_text)\n",
    "\n",
    "    if sim_score >= similarity_threshold:\n",
    "        return f'Plagiarism Detected (SBERT Score: {sim_score:.4f} >= {similarity_threshold})'\n",
    "    else:\n",
    "        return f'No Plagiarism (SBERT Score: {sim_score:.4f} < {similarity_threshold})'"
   ],
   "id": "81877c26c0ad994f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:48.106734Z",
     "start_time": "2025-10-14T17:26:48.041376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "corpus = data[\"combined_text\"]\n",
    "\n",
    "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,5), max_features=20000)\n",
    "X_char = tfidf_char.fit_transform(corpus)\n",
    "\n",
    "X_combined = hstack([X, X_char])"
   ],
   "id": "ad32c7c629206714",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:48.371825Z",
     "start_time": "2025-10-14T17:26:48.114145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# example ( it has no plagiarism)\n",
    "input_text = 'Playing musical instruments enhances creativity.'\n",
    "detect(input_text)"
   ],
   "id": "e97a46c1bc519f67",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Plagiarism (SBERT Score: 0.0952 < 0.6)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:48.415856Z",
     "start_time": "2025-10-14T17:26:48.378113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# example ( it has no plagarism)\n",
    "input_text = 'Practicing yoga enhances physical flexibility.'\n",
    "detect(input_text)"
   ],
   "id": "4c7af2241e2f6b21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Plagiarism (SBERT Score: 0.0373 < 0.6)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T17:26:48.460271Z",
     "start_time": "2025-10-14T17:26:48.422903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# example ( it is a plagarized text)\n",
    "input_text = 'Researchers have discovered a new species of butterfly in the Amazon rainforest.'\n",
    "detect(input_text)"
   ],
   "id": "e8baa4a3eea3dd7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plagiarism Detected (SBERT Score: 1.0000 >= 0.6)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
